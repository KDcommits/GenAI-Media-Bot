{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\krish\\anaconda3\\envs\\torch_env\\lib\\site-packages\\pinecone\\index.py:4: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import re\n",
    "import time\n",
    "import copy\n",
    "import fitz\n",
    "import numpy as np\n",
    "import pinecone as pc\n",
    "from tqdm.auto import tqdm\n",
    "from dotenv import load_dotenv\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.vectorstores import  Pinecone ,FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "class CustomTextSplitter:\n",
    "\n",
    "    def __init__(self, chunk_size, chunk_overlap):\n",
    "        self.keep_separator= False\n",
    "        self.strip_whitespace=True\n",
    "        self.is_separator_regex=False\n",
    "        self.add_start_index=False\n",
    "        self.length_function = len\n",
    "        self.chunk_size=chunk_size\n",
    "        self.chunk_overlap = chunk_overlap\n",
    "        self.separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "\n",
    "    def _split_text_with_regex(self,text: str, separator: str):\n",
    "        # Now that we have the separator, split the text\n",
    "        if separator:\n",
    "            if self.keep_separator:\n",
    "                # The parentheses in the pattern keep the delimiters in the result.\n",
    "                _splits = re.split(f\"({separator})\", text)\n",
    "                splits = [_splits[i] + _splits[i + 1] for i in range(1, len(_splits), 2)]\n",
    "                if len(_splits) % 2 == 0:\n",
    "                    splits += _splits[-1:]\n",
    "                splits = [_splits[0]] + splits\n",
    "            else:\n",
    "                splits = re.split(separator, text)\n",
    "        else:\n",
    "            splits = list(text)\n",
    "        return [s for s in splits if s != \"\"]\n",
    "    \n",
    "    def _join_docs(self, docs, separator:str,):\n",
    "        text = separator.join(docs)\n",
    "        if self.strip_whitespace:\n",
    "            text = text.strip()\n",
    "        if text == \"\":\n",
    "            return None\n",
    "        else:\n",
    "            return text\n",
    "        \n",
    "\n",
    "    def _merge_splits(self, splits, separator: str):\n",
    "        # We now want to combine these smaller pieces into medium size\n",
    "        # chunks to send to the LLM.\n",
    "        separator_len = self.length_function(separator)\n",
    "\n",
    "        docs = []\n",
    "        current_doc= []\n",
    "        total = 0\n",
    "        for d in splits:\n",
    "            _len = self.length_function(d)\n",
    "            if (\n",
    "                total + _len + (separator_len if len(current_doc) > 0 else 0)\n",
    "                > self.chunk_size\n",
    "            ):\n",
    "                if total > self.chunk_size:\n",
    "                    print(\n",
    "                        f\"Created a chunk of size {total}, \"\n",
    "                        f\"which is longer than the specified {self.chunk_size}\"\n",
    "                    )\n",
    "                if len(current_doc) > 0:\n",
    "                    doc = self._join_docs(current_doc, separator)\n",
    "                    if doc is not None:\n",
    "                        docs.append(doc)\n",
    "                    # Keep on popping if:\n",
    "                    # - we have a larger chunk than in the chunk overlap\n",
    "                    # - or if we still have any chunks and the length is long\n",
    "                    while total > self.chunk_overlap or (\n",
    "                        total + _len + (separator_len if len(current_doc) > 0 else 0)\n",
    "                        > self.chunk_size\n",
    "                        and total > 0\n",
    "                    ):\n",
    "                        total -= self.length_function(current_doc[0]) + (\n",
    "                            separator_len if len(current_doc) > 1 else 0\n",
    "                        )\n",
    "                        current_doc = current_doc[1:]\n",
    "            current_doc.append(d)\n",
    "            total += _len + (separator_len if len(current_doc) > 1 else 0)\n",
    "        doc = self._join_docs(current_doc, separator)\n",
    "        if doc is not None:\n",
    "            docs.append(doc)\n",
    "        return docs\n",
    "    \n",
    "    def _split_text(self,text: str,):\n",
    "        \"\"\"Split incoming text and return chunks.\"\"\"\n",
    "        final_chunks = []\n",
    "        # Get appropriate separator to use\n",
    "        separator = self.separators[-1]\n",
    "        new_separators = []\n",
    "        for i, _s in enumerate(self.separators):\n",
    "            _separator = _s if self.is_separator_regex else re.escape(_s)\n",
    "            if _s == \"\":\n",
    "                separator = _s\n",
    "                break\n",
    "            if re.search(_separator, text):\n",
    "                separator = _s\n",
    "                new_separators = self.separators[i + 1 :]\n",
    "                break\n",
    "\n",
    "        _separator = separator if self.is_separator_regex else re.escape(separator)\n",
    "        splits = self._split_text_with_regex(text, _separator)\n",
    "\n",
    "        # Now go merging things, recursively splitting longer texts.\n",
    "        _good_splits = []\n",
    "        _separator = \"\" if self.keep_separator else separator\n",
    "        for s in splits:\n",
    "            if self.length_function(s) < self.chunk_size:\n",
    "                _good_splits.append(s)\n",
    "            else:\n",
    "                if _good_splits:\n",
    "                    merged_text = self._merge_splits(_good_splits, _separator)\n",
    "                    final_chunks.extend(merged_text)\n",
    "                    _good_splits = []\n",
    "                if not new_separators:\n",
    "                    final_chunks.append(s)\n",
    "                else:\n",
    "                    other_info = self._split_text(s, new_separators)\n",
    "                    final_chunks.extend(other_info)\n",
    "        if _good_splits:\n",
    "            merged_text = self._merge_splits(_good_splits, _separator)\n",
    "            final_chunks.extend(merged_text)\n",
    "        return final_chunks\n",
    "    \n",
    "\n",
    "    def create_documents(self, texts, pdf_name):\n",
    "        \"\"\"Create documents from a list of texts.\"\"\"\n",
    "        documents = []\n",
    "        for i, text in enumerate(texts):\n",
    "            index = -1\n",
    "            for chunk in self._split_text(text):\n",
    "                if self.add_start_index:\n",
    "                    index = text.find(chunk, index + 1)\n",
    "                new_doc = Document(page_content=chunk, metadata={})\n",
    "                new_doc.metadata['source'] = pdf_name\n",
    "                documents.append(new_doc)\n",
    "        return documents\n",
    "    \n",
    "class PdfTextExtractor:\n",
    "    def __init__(self, pdf_path):\n",
    "        self.pdf_path = pdf_path \n",
    "        self.start_page = 1\n",
    "        self.end_page = None\n",
    "\n",
    "    def _preprocess(self,text):\n",
    "        '''\n",
    "        preprocess extrcted text from pdf\n",
    "        1. Replace new line character with whitespace.\n",
    "        2. Replace redundant whitespace with a single whitespace\n",
    "        '''\n",
    "        text = text.replace('\\n', ' ')\n",
    "        text = re.sub('\\s+', ' ', text)\n",
    "        text = re.sub(r'\\\\u[e-f][0-9a-z]{3}',' ', text)\n",
    "        return text\n",
    "    \n",
    "    def _pdf_to_text(self, pdf_filename):\n",
    "        '''\n",
    "            convert pdf to a list of words.\n",
    "        '''\n",
    "        doc = fitz.open(self.pdf_path)\n",
    "        total_pages= doc.page_count\n",
    "\n",
    "        if self.end_page is None:\n",
    "            self.end_page = total_pages\n",
    "        text_list=[]\n",
    "\n",
    "        for i in tqdm(range(self.start_page-1, self.end_page)):\n",
    "            text= doc.load_page(i).get_text('text')\n",
    "            text= self._preprocess(text)\n",
    "            text_list.append(f'[{pdf_filename}, page:{i+1}] '+text+ f' [{pdf_filename}, page:{i+1}]')\n",
    "        doc.close()\n",
    "        return text_list\n",
    "    \n",
    "\n",
    "\n",
    "class Data:\n",
    "\n",
    "    def __init__(self, pdf_data_path, vector_db_path):\n",
    "\n",
    "        self.pdf_data_path = pdf_data_path\n",
    "        self.vector_db_path = vector_db_path\n",
    "        self.pinecone_api_key = os.getenv('PINECONE_KEY')\n",
    "        self.pinecone_env = os.getenv('PINECONE_ENV')\n",
    "        self.embedding_model = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "        self.openai_embedding_model = OpenAIEmbeddings(model='text-embedding-ada-002',\n",
    "                                                        openai_api_key=os.getenv('OPENAI_KEY'))\n",
    "        \n",
    "    def createPDFVectorDBwithFAISS(self, chunk_size, chunk_overlap):\n",
    "        document_list=[]\n",
    "        for pdf_filename in os.listdir(self.pdf_data_path):\n",
    "            pdf_file_path = os.path.join(self.pdf_data_path,pdf_filename)\n",
    "            extracted_text_list = PdfTextExtractor(pdf_file_path)._pdf_to_text(pdf_filename)\n",
    "            merged_text_list = ['.'.join(extracted_text_list)]\n",
    "            splitter = CustomTextSplitter(chunk_size, chunk_overlap)\n",
    "            docs  = splitter.create_documents(merged_text_list,pdf_filename)\n",
    "            document_list.extend(docs)\n",
    "    \n",
    "        db = FAISS.from_documents(document_list, self.embedding_model)\n",
    "        db.save_local(self.vector_db_path)\n",
    "\n",
    "    def create_top_k_chunk_from_FAISS(self, question,top_k):\n",
    "        test_idex = FAISS.load_local(self.vector_db_path,self.embedding_model)\n",
    "        top_k_chunks  = test_idex.similarity_search(question,k=top_k)\n",
    "        return top_k_chunks\n",
    "    \n",
    "    def fetch_FAISS_VectorDB(self):\n",
    "        test_index = FAISS.load_local(self.vector_db_path,self.embedding_model)\n",
    "        return test_index\n",
    "    \n",
    "\n",
    "    def createPDFVectorDBwithPinecone(self,chunk_size, chunk_overlap):\n",
    "        document_list=[]\n",
    "        for pdf_filename in os.listdir(self.pdf_data_path):\n",
    "            pdf_file_path = os.path.join(self.pdf_data_path,pdf_filename)\n",
    "            extracted_text_list = PdfTextExtractor(pdf_file_path)._pdf_to_text(pdf_filename)\n",
    "            merged_text_list = ['.'.join(extracted_text_list)]\n",
    "            splitter = CustomTextSplitter(chunk_size, chunk_overlap)\n",
    "            docs  = splitter.create_documents(merged_text_list,pdf_filename)\n",
    "            document_list.extend(docs)\n",
    "\n",
    "        embeddings = []\n",
    "        ids = []\n",
    "        metadatas = []\n",
    "        for i in range(len(document_list)):\n",
    "            if i%5==0:\n",
    "                time.sleep(5)\n",
    "            page_content = document_list[i].page_content\n",
    "            source_pdf = document_list[i].metadata['source'].split('\\\\')[-1]\n",
    "            embedded_page_content = self.openai_embedding_model.embed_query(page_content)\n",
    "            metadata = {\n",
    "                'source' : source_pdf,\n",
    "                'page_content' : page_content\n",
    "            }\n",
    "            ids.append(str(i))\n",
    "            embeddings.append(embedded_page_content)\n",
    "            metadatas.append(metadata)\n",
    "\n",
    "        pc.init(api_key=self.pinecone_api_key, environment=self.pinecone_env)\n",
    "        index = pc.Index('pdf-index')\n",
    "        index.upsert(vectors = zip(ids, embeddings, metadatas))\n",
    "\n",
    "    def create_top_k_chunk_from_Pinecone(self, question,top_k):\n",
    "        pc.init(api_key=self.pinecone_api_key, environment=self.pinecone_env)\n",
    "        index = pc.Index('pdf-index')\n",
    "        vectorstore = Pinecone( index, self.openai_embedding_model.embed_query, text_key='page_content')\n",
    "        top_k_chunks = vectorstore.similarity_search(question, k=top_k)\n",
    "        return top_k_chunks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58/58 [00:00<00:00, 462.71it/s]\n",
      "100%|██████████| 281/281 [00:00<00:00, 311.25it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 373.05it/s]\n"
     ]
    }
   ],
   "source": [
    "pdf_data_path = \".\\\\media\"\n",
    "pdf_vector_embedding_path = \".\\\\VectorDB\"\n",
    "data_obj = Data(pdf_data_path,pdf_vector_embedding_path)\n",
    "data_obj.createPDFVectorDBwithFAISS(chunk_size=2000, chunk_overlap=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='key to a nation’s progress. Our government is committed to providing a transparent and accountable administration which works for the betterment and welfare of the common citizen,” said Hon’ble Prime Minister. [budget_2023.pdf, page:17].[budget_2023.pdf, page:18] 14 Mission Karmayogi 58. Under Mission Karmayogi, Centre, States and Union Territories are making and implementing capacity-building plans for civil servants. The government has also launched an integrated online training platform, iGOT Karmayogi, to provide continuous learning opportunities for lakhs of government employees to upgrade their skills and facilitate people-centric approach. 59. For enhancing ease of doing business, more than 39,000 compliances have been reduced and more than 3,400 legal provisions have been decriminalized. For furthering the trust- based governance, we have introduced the Jan Vishwas Bill to amend 42 Central Acts. This Budget proposes a series of measures to unleash the potential of our economy. Centres of Excellence for Artificial Intelligence 60. For realizing the vision of “Make AI in India and Make AI work for India”, three centres of excellence for Artificial Intelligence will be set-up in top educational institutions. Leading industry players will partner in conducting interdisciplinary research, develop cutting-edge applications and scalable problem solutions in the areas of agriculture, health, and sustainable cities. This will galvanize an effective AI ecosystem and nurture quality human resources in the field. National Data Governance Policy 61. To unleash innovation and research by start-ups and academia, a National Data Governance Policy will be brought out. This will enable access to anonymized data. Simplification of Know Your Customer (KYC) process 62. The KYC process will be simplified adopting a ‘risk-based’ instead of ‘one size fits all’ approach. The financial sector regulators will also be [budget_2023.pdf, page:18].[budget_2023.pdf, page:19] 15 encouraged', metadata={'source': 'budget_2023.pdf'}),\n",
       " Document(page_content='Inscriptions’ will be set up in a digital epigraphy museum, with digitization of one lakh ancient inscriptions in the first stage. Support for poor prisoners 42. For poor persons who are in prisons and unable to afford the penalty or the bail amount, required financial support will be provided. Priority 3: Infrastructure & Investment 43. Investments in Infrastructure and productive capacity have a large multiplier impact on growth and employment. After the subdued period of the pandemic, private investments are growing again. The Budget takes the lead once again to ramp up the virtuous cycle of investment and job creation. Capital Investment as driver of growth and jobs 44. Capital investment outlay is being increased steeply for the third year in a row by 33 per cent to ` 10 lakh crore, which would be 3.3 per cent of GDP. This will be almost three times the outlay in 2019-20. 45. This substantial increase in recent years is central to the government’s efforts to enhance growth potential and job creation, crowd- in private investments, and provide a cushion against global headwinds. Effective Capital Expenditure 46. The direct capital investment by the Centre is complemented by the provision made for creation of capital assets through Grants-in-Aid to States. The ‘Effective Capital Expenditure’ of the Centre is budgeted at ` 13.7 lakh crore, which will be 4.5 per cent of GDP. [budget_2023.pdf, page:15].[budget_2023.pdf, page:16] 12 Support to State Governments for Capital Investment 47. I have decided to continue the 50-year interest free loan to state governments for one more year to spur investment in infrastructure and to incentivize them for complementary policy actions, with a significantly enhanced outlay of ` 1.3 lakh crore. Enhancing opportunities for private investment in Infrastructure 48. The newly established Infrastructure Finance Secretariat will assist all stakeholders for more private investment in infrastructure, including railways, roads, urban', metadata={'source': 'budget_2023.pdf'}),\n",
       " Document(page_content='payments, and social security. This will greatly benefit the Scheduled Castes, Scheduled Tribes, OBCs, women and people belonging to the weaker sections. 3) Tourism: The country offers immense attraction for domestic as well as foreign tourists. There is a large potential to be tapped in tourism. The sector holds huge opportunities for jobs and entrepreneurship for youth in particular. Promotion of tourism will be taken up on mission mode, with active participation of states, convergence of government programmes and public-private partnerships. [budget_2023.pdf, page:8].[budget_2023.pdf, page:9] 5 4) Green Growth: We are implementing many programmes for green fuel, green energy, green farming, green mobility, green buildings, and green equipment, and policies for efficient use of energy across various economic sectors. These green growth efforts help in reducing carbon intensity of the economy and provides for large- scale green job opportunities. Priorities of this Budget 14. The Budget adopts the following seven priorities. They complement each other and act as the ‘Saptarishi’ guiding us through the Amrit Kaal. 1) Inclusive Development 2) Reaching the Last Mile 3) Infrastructure and Investment 4) Unleashing the Potential 5) Green Growth 6) Youth Power 7) Financial Sector Priority 1: Inclusive Development 15. The Government’s philosophy of Sabka Saath Sabka Vikas has facilitated inclusive development covering in specific, farmers, women, youth, OBCs, Scheduled Castes, Scheduled Tribes, divyangjan and economically weaker sections, and overall priority for the underprivileged (vanchiton ko variyata). There has also been a sustained focus on Jammu & Kashmir, Ladakh and the North-East. This Budget builds on those efforts. Agriculture and Cooperation Digital Public Infrastructure for Agriculture 16. Digital public infrastructure for agriculture will be built as an open source, open standard and inter operable public good. This will enable [budget_2023.pdf,', metadata={'source': 'budget_2023.pdf'})]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_question = \"Artificial Intelligence in budget?\"\n",
    "result = data_obj.create_top_k_chunk_from_FAISS(test_question, top_k =3)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krish\\AppData\\Roaming\\Python\\Python310\\site-packages\\langchain\\vectorstores\\pinecone.py:61: UserWarning: Passing in `embedding` as a Callable is deprecated. Please pass in an Embeddings object instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "PineconeProtocolError",
     "evalue": "Failed to connect; did you specify the correct index name?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionResetError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\krish\\anaconda3\\envs\\torch_env\\lib\\site-packages\\urllib3\\connectionpool.py:714\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    713\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 714\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[0;32m    715\u001b[0m     conn,\n\u001b[0;32m    716\u001b[0m     method,\n\u001b[0;32m    717\u001b[0m     url,\n\u001b[0;32m    718\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[0;32m    719\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[0;32m    720\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    721\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    722\u001b[0m )\n\u001b[0;32m    724\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    725\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    726\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    727\u001b[0m \u001b[39m# mess.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\krish\\anaconda3\\envs\\torch_env\\lib\\site-packages\\urllib3\\connectionpool.py:403\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    402\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_conn(conn)\n\u001b[0;32m    404\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    405\u001b[0m     \u001b[39m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\krish\\anaconda3\\envs\\torch_env\\lib\\site-packages\\urllib3\\connectionpool.py:1053\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mgetattr\u001b[39m(conn, \u001b[39m\"\u001b[39m\u001b[39msock\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):  \u001b[39m# AppEngine might not have  `.sock`\u001b[39;00m\n\u001b[1;32m-> 1053\u001b[0m     conn\u001b[39m.\u001b[39;49mconnect()\n\u001b[0;32m   1055\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m conn\u001b[39m.\u001b[39mis_verified:\n",
      "File \u001b[1;32mc:\\Users\\krish\\anaconda3\\envs\\torch_env\\lib\\site-packages\\urllib3\\connection.py:419\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    417\u001b[0m     context\u001b[39m.\u001b[39mload_default_certs()\n\u001b[1;32m--> 419\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock \u001b[39m=\u001b[39m ssl_wrap_socket(\n\u001b[0;32m    420\u001b[0m     sock\u001b[39m=\u001b[39;49mconn,\n\u001b[0;32m    421\u001b[0m     keyfile\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkey_file,\n\u001b[0;32m    422\u001b[0m     certfile\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcert_file,\n\u001b[0;32m    423\u001b[0m     key_password\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkey_password,\n\u001b[0;32m    424\u001b[0m     ca_certs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mca_certs,\n\u001b[0;32m    425\u001b[0m     ca_cert_dir\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mca_cert_dir,\n\u001b[0;32m    426\u001b[0m     ca_cert_data\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mca_cert_data,\n\u001b[0;32m    427\u001b[0m     server_hostname\u001b[39m=\u001b[39;49mserver_hostname,\n\u001b[0;32m    428\u001b[0m     ssl_context\u001b[39m=\u001b[39;49mcontext,\n\u001b[0;32m    429\u001b[0m     tls_in_tls\u001b[39m=\u001b[39;49mtls_in_tls,\n\u001b[0;32m    430\u001b[0m )\n\u001b[0;32m    432\u001b[0m \u001b[39m# If we're using all defaults and the connection\u001b[39;00m\n\u001b[0;32m    433\u001b[0m \u001b[39m# is TLSv1 or TLSv1.1 we throw a DeprecationWarning\u001b[39;00m\n\u001b[0;32m    434\u001b[0m \u001b[39m# for the host.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\krish\\anaconda3\\envs\\torch_env\\lib\\site-packages\\urllib3\\util\\ssl_.py:449\u001b[0m, in \u001b[0;36mssl_wrap_socket\u001b[1;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[39mif\u001b[39;00m send_sni:\n\u001b[1;32m--> 449\u001b[0m     ssl_sock \u001b[39m=\u001b[39m _ssl_wrap_socket_impl(\n\u001b[0;32m    450\u001b[0m         sock, context, tls_in_tls, server_hostname\u001b[39m=\u001b[39;49mserver_hostname\n\u001b[0;32m    451\u001b[0m     )\n\u001b[0;32m    452\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\krish\\anaconda3\\envs\\torch_env\\lib\\site-packages\\urllib3\\util\\ssl_.py:493\u001b[0m, in \u001b[0;36m_ssl_wrap_socket_impl\u001b[1;34m(sock, ssl_context, tls_in_tls, server_hostname)\u001b[0m\n\u001b[0;32m    492\u001b[0m \u001b[39mif\u001b[39;00m server_hostname:\n\u001b[1;32m--> 493\u001b[0m     \u001b[39mreturn\u001b[39;00m ssl_context\u001b[39m.\u001b[39;49mwrap_socket(sock, server_hostname\u001b[39m=\u001b[39;49mserver_hostname)\n\u001b[0;32m    494\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\krish\\anaconda3\\envs\\torch_env\\lib\\ssl.py:513\u001b[0m, in \u001b[0;36mSSLContext.wrap_socket\u001b[1;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[0;32m    507\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrap_socket\u001b[39m(\u001b[39mself\u001b[39m, sock, server_side\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    508\u001b[0m                 do_handshake_on_connect\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    509\u001b[0m                 suppress_ragged_eofs\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    510\u001b[0m                 server_hostname\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, session\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    511\u001b[0m     \u001b[39m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[0;32m    512\u001b[0m     \u001b[39m# ctx._wrap_socket()\u001b[39;00m\n\u001b[1;32m--> 513\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msslsocket_class\u001b[39m.\u001b[39;49m_create(\n\u001b[0;32m    514\u001b[0m         sock\u001b[39m=\u001b[39;49msock,\n\u001b[0;32m    515\u001b[0m         server_side\u001b[39m=\u001b[39;49mserver_side,\n\u001b[0;32m    516\u001b[0m         do_handshake_on_connect\u001b[39m=\u001b[39;49mdo_handshake_on_connect,\n\u001b[0;32m    517\u001b[0m         suppress_ragged_eofs\u001b[39m=\u001b[39;49msuppress_ragged_eofs,\n\u001b[0;32m    518\u001b[0m         server_hostname\u001b[39m=\u001b[39;49mserver_hostname,\n\u001b[0;32m    519\u001b[0m         context\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m    520\u001b[0m         session\u001b[39m=\u001b[39;49msession\n\u001b[0;32m    521\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\krish\\anaconda3\\envs\\torch_env\\lib\\ssl.py:1071\u001b[0m, in \u001b[0;36mSSLSocket._create\u001b[1;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[0;32m   1070\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1071\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdo_handshake()\n\u001b[0;32m   1072\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mOSError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\krish\\anaconda3\\envs\\torch_env\\lib\\ssl.py:1342\u001b[0m, in \u001b[0;36mSSLSocket.do_handshake\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m   1341\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msettimeout(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m-> 1342\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mdo_handshake()\n\u001b[0;32m   1343\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "\u001b[1;31mConnectionResetError\u001b[0m: [WinError 10054] An existing connection was forcibly closed by the remote host",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mProtocolError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\krish\\anaconda3\\envs\\torch_env\\lib\\site-packages\\pinecone\\core\\utils\\error_handling.py:17\u001b[0m, in \u001b[0;36mvalidate_and_convert_errors.<locals>.inner_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 17\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     18\u001b[0m \u001b[39mexcept\u001b[39;00m MaxRetryError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\krish\\anaconda3\\envs\\torch_env\\lib\\site-packages\\pinecone\\index.py:455\u001b[0m, in \u001b[0;36mIndex.query\u001b[1;34m(self, vector, id, queries, top_k, namespace, filter, include_values, include_metadata, sparse_vector, **kwargs)\u001b[0m\n\u001b[0;32m    446\u001b[0m args_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parse_non_empty_args([(\u001b[39m'\u001b[39m\u001b[39mvector\u001b[39m\u001b[39m'\u001b[39m, vector),\n\u001b[0;32m    447\u001b[0m                                         (\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mid\u001b[39m),\n\u001b[0;32m    448\u001b[0m                                         (\u001b[39m'\u001b[39m\u001b[39mqueries\u001b[39m\u001b[39m'\u001b[39m, queries),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    453\u001b[0m                                         (\u001b[39m'\u001b[39m\u001b[39minclude_metadata\u001b[39m\u001b[39m'\u001b[39m, include_metadata),\n\u001b[0;32m    454\u001b[0m                                         (\u001b[39m'\u001b[39m\u001b[39msparse_vector\u001b[39m\u001b[39m'\u001b[39m, sparse_vector)])\n\u001b[1;32m--> 455\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_vector_api\u001b[39m.\u001b[39mquery(\n\u001b[0;32m    456\u001b[0m     QueryRequest(\n\u001b[0;32m    457\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39margs_dict,\n\u001b[0;32m    458\u001b[0m         _check_type\u001b[39m=\u001b[39m_check_type,\n\u001b[0;32m    459\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m kwargs\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m _OPENAPI_ENDPOINT_PARAMS}\n\u001b[0;32m    460\u001b[0m     ),\n\u001b[0;32m    461\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m kwargs\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k \u001b[39min\u001b[39;00m _OPENAPI_ENDPOINT_PARAMS}\n\u001b[0;32m    462\u001b[0m )\n\u001b[0;32m    463\u001b[0m \u001b[39mreturn\u001b[39;00m parse_query_response(response, vector \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mid\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\krish\\anaconda3\\envs\\torch_env\\lib\\site-packages\\pinecone\\core\\client\\api_client.py:776\u001b[0m, in \u001b[0;36mEndpoint.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    766\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\" This method is invoked when endpoints are called\u001b[39;00m\n\u001b[0;32m    767\u001b[0m \u001b[39mExample:\u001b[39;00m\n\u001b[0;32m    768\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    774\u001b[0m \n\u001b[0;32m    775\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 776\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallable(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\krish\\anaconda3\\envs\\torch_env\\lib\\site-packages\\pinecone\\core\\client\\api\\vector_operations_api.py:716\u001b[0m, in \u001b[0;36mVectorOperationsApi.__init__.<locals>.__query\u001b[1;34m(self, query_request, **kwargs)\u001b[0m\n\u001b[0;32m    714\u001b[0m kwargs[\u001b[39m'\u001b[39m\u001b[39mquery_request\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \\\n\u001b[0;32m    715\u001b[0m     query_request\n\u001b[1;32m--> 716\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcall_with_http_info(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\krish\\anaconda3\\envs\\torch_env\\lib\\site-packages\\pinecone\\core\\client\\api_client.py:838\u001b[0m, in \u001b[0;36mEndpoint.call_with_http_info\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    836\u001b[0m     params[\u001b[39m'\u001b[39m\u001b[39mheader\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mContent-Type\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m header_list\n\u001b[1;32m--> 838\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapi_client\u001b[39m.\u001b[39;49mcall_api(\n\u001b[0;32m    839\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msettings[\u001b[39m'\u001b[39;49m\u001b[39mendpoint_path\u001b[39;49m\u001b[39m'\u001b[39;49m], \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msettings[\u001b[39m'\u001b[39;49m\u001b[39mhttp_method\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    840\u001b[0m     params[\u001b[39m'\u001b[39;49m\u001b[39mpath\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    841\u001b[0m     params[\u001b[39m'\u001b[39;49m\u001b[39mquery\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    842\u001b[0m     params[\u001b[39m'\u001b[39;49m\u001b[39mheader\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    843\u001b[0m     body\u001b[39m=\u001b[39;49mparams[\u001b[39m'\u001b[39;49m\u001b[39mbody\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    844\u001b[0m     post_params\u001b[39m=\u001b[39;49mparams[\u001b[39m'\u001b[39;49m\u001b[39mform\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    845\u001b[0m     files\u001b[39m=\u001b[39;49mparams[\u001b[39m'\u001b[39;49m\u001b[39mfile\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    846\u001b[0m     response_type\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msettings[\u001b[39m'\u001b[39;49m\u001b[39mresponse_type\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    847\u001b[0m     auth_settings\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msettings[\u001b[39m'\u001b[39;49m\u001b[39mauth\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    848\u001b[0m     async_req\u001b[39m=\u001b[39;49mkwargs[\u001b[39m'\u001b[39;49m\u001b[39masync_req\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    849\u001b[0m     _check_type\u001b[39m=\u001b[39;49mkwargs[\u001b[39m'\u001b[39;49m\u001b[39m_check_return_type\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    850\u001b[0m     _return_http_data_only\u001b[39m=\u001b[39;49mkwargs[\u001b[39m'\u001b[39;49m\u001b[39m_return_http_data_only\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    851\u001b[0m     _preload_content\u001b[39m=\u001b[39;49mkwargs[\u001b[39m'\u001b[39;49m\u001b[39m_preload_content\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    852\u001b[0m     _request_timeout\u001b[39m=\u001b[39;49mkwargs[\u001b[39m'\u001b[39;49m\u001b[39m_request_timeout\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    853\u001b[0m     _host\u001b[39m=\u001b[39;49m_host,\n\u001b[0;32m    854\u001b[0m     collection_formats\u001b[39m=\u001b[39;49mparams[\u001b[39m'\u001b[39;49m\u001b[39mcollection_format\u001b[39;49m\u001b[39m'\u001b[39;49m])\n",
      "File \u001b[1;32mc:\\Users\\krish\\anaconda3\\envs\\torch_env\\lib\\site-packages\\pinecone\\core\\client\\api_client.py:413\u001b[0m, in \u001b[0;36mApiClient.call_api\u001b[1;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, async_req, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[0m\n\u001b[0;32m    412\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m async_req:\n\u001b[1;32m--> 413\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__call_api(resource_path, method,\n\u001b[0;32m    414\u001b[0m                            path_params, query_params, header_params,\n\u001b[0;32m    415\u001b[0m                            body, post_params, files,\n\u001b[0;32m    416\u001b[0m                            response_type, auth_settings,\n\u001b[0;32m    417\u001b[0m                            _return_http_data_only, collection_formats,\n\u001b[0;32m    418\u001b[0m                            _preload_content, _request_timeout, _host,\n\u001b[0;32m    419\u001b[0m                            _check_type)\n\u001b[0;32m    421\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool\u001b[39m.\u001b[39mapply_async(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__call_api, (resource_path,\n\u001b[0;32m    422\u001b[0m                                                method, path_params,\n\u001b[0;32m    423\u001b[0m                                                query_params,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    431\u001b[0m                                                _request_timeout,\n\u001b[0;32m    432\u001b[0m                                                _host, _check_type))\n",
      "File \u001b[1;32mc:\\Users\\krish\\anaconda3\\envs\\torch_env\\lib\\site-packages\\pinecone\\core\\client\\api_client.py:200\u001b[0m, in \u001b[0;36mApiClient.__call_api\u001b[1;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    199\u001b[0m     \u001b[39m# perform request and return response\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m     response_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    201\u001b[0m         method, url, query_params\u001b[39m=\u001b[39;49mquery_params, headers\u001b[39m=\u001b[39;49mheader_params,\n\u001b[0;32m    202\u001b[0m         post_params\u001b[39m=\u001b[39;49mpost_params, body\u001b[39m=\u001b[39;49mbody,\n\u001b[0;32m    203\u001b[0m         _preload_content\u001b[39m=\u001b[39;49m_preload_content,\n\u001b[0;32m    204\u001b[0m         _request_timeout\u001b[39m=\u001b[39;49m_request_timeout)\n\u001b[0;32m    205\u001b[0m \u001b[39mexcept\u001b[39;00m ApiException \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\krish\\anaconda3\\envs\\torch_env\\lib\\site-packages\\pinecone\\core\\client\\api_client.py:459\u001b[0m, in \u001b[0;36mApiClient.request\u001b[1;34m(self, method, url, query_params, headers, post_params, body, _preload_content, _request_timeout)\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[39melif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mPOST\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 459\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrest_client\u001b[39m.\u001b[39;49mPOST(url,\n\u001b[0;32m    460\u001b[0m                                  query_params\u001b[39m=\u001b[39;49mquery_params,\n\u001b[0;32m    461\u001b[0m                                  headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    462\u001b[0m                                  post_params\u001b[39m=\u001b[39;49mpost_params,\n\u001b[0;32m    463\u001b[0m                                  _preload_content\u001b[39m=\u001b[39;49m_preload_content,\n\u001b[0;32m    464\u001b[0m                                  _request_timeout\u001b[39m=\u001b[39;49m_request_timeout,\n\u001b[0;32m    465\u001b[0m                                  body\u001b[39m=\u001b[39;49mbody)\n\u001b[0;32m    466\u001b[0m \u001b[39melif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mPUT\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\krish\\anaconda3\\envs\\torch_env\\lib\\site-packages\\pinecone\\core\\client\\rest.py:271\u001b[0m, in \u001b[0;36mRESTClientObject.POST\u001b[1;34m(self, url, headers, query_params, post_params, body, _preload_content, _request_timeout)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mPOST\u001b[39m(\u001b[39mself\u001b[39m, url, headers\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, query_params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, post_params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    270\u001b[0m          body\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, _preload_content\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, _request_timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m--> 271\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(\u001b[39m\"\u001b[39;49m\u001b[39mPOST\u001b[39;49m\u001b[39m\"\u001b[39;49m, url,\n\u001b[0;32m    272\u001b[0m                         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    273\u001b[0m                         query_params\u001b[39m=\u001b[39;49mquery_params,\n\u001b[0;32m    274\u001b[0m                         post_params\u001b[39m=\u001b[39;49mpost_params,\n\u001b[0;32m    275\u001b[0m                         _preload_content\u001b[39m=\u001b[39;49m_preload_content,\n\u001b[0;32m    276\u001b[0m                         _request_timeout\u001b[39m=\u001b[39;49m_request_timeout,\n\u001b[0;32m    277\u001b[0m                         body\u001b[39m=\u001b[39;49mbody)\n",
      "File \u001b[1;32mc:\\Users\\krish\\anaconda3\\envs\\torch_env\\lib\\site-packages\\pinecone\\core\\client\\rest.py:157\u001b[0m, in \u001b[0;36mRESTClientObject.request\u001b[1;34m(self, method, url, query_params, headers, body, post_params, _preload_content, _request_timeout)\u001b[0m\n\u001b[0;32m    156\u001b[0m         request_body \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mdumps(body)\n\u001b[1;32m--> 157\u001b[0m     r \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpool_manager\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    158\u001b[0m         method, url,\n\u001b[0;32m    159\u001b[0m         body\u001b[39m=\u001b[39;49mrequest_body,\n\u001b[0;32m    160\u001b[0m         preload_content\u001b[39m=\u001b[39;49m_preload_content,\n\u001b[0;32m    161\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    162\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders)\n\u001b[0;32m    163\u001b[0m \u001b[39melif\u001b[39;00m headers[\u001b[39m'\u001b[39m\u001b[39mContent-Type\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mapplication/x-www-form-urlencoded\u001b[39m\u001b[39m'\u001b[39m:  \u001b[39m# noqa: E501\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\krish\\anaconda3\\envs\\torch_env\\lib\\site-packages\\urllib3\\request.py:78\u001b[0m, in \u001b[0;36mRequestMethods.request\u001b[1;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 78\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_encode_body(\n\u001b[0;32m     79\u001b[0m         method, url, fields\u001b[39m=\u001b[39mfields, headers\u001b[39m=\u001b[39mheaders, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39murlopen_kw\n\u001b[0;32m     80\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\krish\\anaconda3\\envs\\torch_env\\lib\\site-packages\\urllib3\\request.py:170\u001b[0m, in \u001b[0;36mRequestMethods.request_encode_body\u001b[1;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[0;32m    168\u001b[0m extra_kw\u001b[39m.\u001b[39mupdate(urlopen_kw)\n\u001b[1;32m--> 170\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39murlopen(method, url, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mextra_kw)\n",
      "File \u001b[1;32mc:\\Users\\krish\\anaconda3\\envs\\torch_env\\lib\\site-packages\\urllib3\\poolmanager.py:376\u001b[0m, in \u001b[0;36mPoolManager.urlopen\u001b[1;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 376\u001b[0m     response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39murlopen(method, u\u001b[39m.\u001b[39mrequest_uri, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n\u001b[0;32m    378\u001b[0m redirect_location \u001b[39m=\u001b[39m redirect \u001b[39mand\u001b[39;00m response\u001b[39m.\u001b[39mget_redirect_location()\n",
      "File \u001b[1;32mc:\\Users\\krish\\anaconda3\\envs\\torch_env\\lib\\site-packages\\urllib3\\connectionpool.py:798\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    796\u001b[0m     e \u001b[39m=\u001b[39m ProtocolError(\u001b[39m\"\u001b[39m\u001b[39mConnection aborted.\u001b[39m\u001b[39m\"\u001b[39m, e)\n\u001b[1;32m--> 798\u001b[0m retries \u001b[39m=\u001b[39m retries\u001b[39m.\u001b[39;49mincrement(\n\u001b[0;32m    799\u001b[0m     method, url, error\u001b[39m=\u001b[39;49me, _pool\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m, _stacktrace\u001b[39m=\u001b[39;49msys\u001b[39m.\u001b[39;49mexc_info()[\u001b[39m2\u001b[39;49m]\n\u001b[0;32m    800\u001b[0m )\n\u001b[0;32m    801\u001b[0m retries\u001b[39m.\u001b[39msleep()\n",
      "File \u001b[1;32mc:\\Users\\krish\\anaconda3\\envs\\torch_env\\lib\\site-packages\\urllib3\\util\\retry.py:550\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    549\u001b[0m \u001b[39mif\u001b[39;00m read \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_method_retryable(method):\n\u001b[1;32m--> 550\u001b[0m     \u001b[39mraise\u001b[39;00m six\u001b[39m.\u001b[39;49mreraise(\u001b[39mtype\u001b[39;49m(error), error, _stacktrace)\n\u001b[0;32m    551\u001b[0m \u001b[39melif\u001b[39;00m read \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\krish\\anaconda3\\envs\\torch_env\\lib\\site-packages\\urllib3\\packages\\six.py:769\u001b[0m, in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    768\u001b[0m \u001b[39mif\u001b[39;00m value\u001b[39m.\u001b[39m__traceback__ \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m tb:\n\u001b[1;32m--> 769\u001b[0m     \u001b[39mraise\u001b[39;00m value\u001b[39m.\u001b[39mwith_traceback(tb)\n\u001b[0;32m    770\u001b[0m \u001b[39mraise\u001b[39;00m value\n",
      "File \u001b[1;32mc:\\Users\\krish\\anaconda3\\envs\\torch_env\\lib\\site-packages\\urllib3\\connectionpool.py:714\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    713\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 714\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[0;32m    715\u001b[0m     conn,\n\u001b[0;32m    716\u001b[0m     method,\n\u001b[0;32m    717\u001b[0m     url,\n\u001b[0;32m    718\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[0;32m    719\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[0;32m    720\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    721\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    722\u001b[0m )\n\u001b[0;32m    724\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    725\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    726\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    727\u001b[0m \u001b[39m# mess.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\krish\\anaconda3\\envs\\torch_env\\lib\\site-packages\\urllib3\\connectionpool.py:403\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    402\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_conn(conn)\n\u001b[0;32m    404\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    405\u001b[0m     \u001b[39m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\krish\\anaconda3\\envs\\torch_env\\lib\\site-packages\\urllib3\\connectionpool.py:1053\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mgetattr\u001b[39m(conn, \u001b[39m\"\u001b[39m\u001b[39msock\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):  \u001b[39m# AppEngine might not have  `.sock`\u001b[39;00m\n\u001b[1;32m-> 1053\u001b[0m     conn\u001b[39m.\u001b[39;49mconnect()\n\u001b[0;32m   1055\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m conn\u001b[39m.\u001b[39mis_verified:\n",
      "File \u001b[1;32mc:\\Users\\krish\\anaconda3\\envs\\torch_env\\lib\\site-packages\\urllib3\\connection.py:419\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    417\u001b[0m     context\u001b[39m.\u001b[39mload_default_certs()\n\u001b[1;32m--> 419\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock \u001b[39m=\u001b[39m ssl_wrap_socket(\n\u001b[0;32m    420\u001b[0m     sock\u001b[39m=\u001b[39;49mconn,\n\u001b[0;32m    421\u001b[0m     keyfile\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkey_file,\n\u001b[0;32m    422\u001b[0m     certfile\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcert_file,\n\u001b[0;32m    423\u001b[0m     key_password\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkey_password,\n\u001b[0;32m    424\u001b[0m     ca_certs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mca_certs,\n\u001b[0;32m    425\u001b[0m     ca_cert_dir\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mca_cert_dir,\n\u001b[0;32m    426\u001b[0m     ca_cert_data\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mca_cert_data,\n\u001b[0;32m    427\u001b[0m     server_hostname\u001b[39m=\u001b[39;49mserver_hostname,\n\u001b[0;32m    428\u001b[0m     ssl_context\u001b[39m=\u001b[39;49mcontext,\n\u001b[0;32m    429\u001b[0m     tls_in_tls\u001b[39m=\u001b[39;49mtls_in_tls,\n\u001b[0;32m    430\u001b[0m )\n\u001b[0;32m    432\u001b[0m \u001b[39m# If we're using all defaults and the connection\u001b[39;00m\n\u001b[0;32m    433\u001b[0m \u001b[39m# is TLSv1 or TLSv1.1 we throw a DeprecationWarning\u001b[39;00m\n\u001b[0;32m    434\u001b[0m \u001b[39m# for the host.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\krish\\anaconda3\\envs\\torch_env\\lib\\site-packages\\urllib3\\util\\ssl_.py:449\u001b[0m, in \u001b[0;36mssl_wrap_socket\u001b[1;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[39mif\u001b[39;00m send_sni:\n\u001b[1;32m--> 449\u001b[0m     ssl_sock \u001b[39m=\u001b[39m _ssl_wrap_socket_impl(\n\u001b[0;32m    450\u001b[0m         sock, context, tls_in_tls, server_hostname\u001b[39m=\u001b[39;49mserver_hostname\n\u001b[0;32m    451\u001b[0m     )\n\u001b[0;32m    452\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\krish\\anaconda3\\envs\\torch_env\\lib\\site-packages\\urllib3\\util\\ssl_.py:493\u001b[0m, in \u001b[0;36m_ssl_wrap_socket_impl\u001b[1;34m(sock, ssl_context, tls_in_tls, server_hostname)\u001b[0m\n\u001b[0;32m    492\u001b[0m \u001b[39mif\u001b[39;00m server_hostname:\n\u001b[1;32m--> 493\u001b[0m     \u001b[39mreturn\u001b[39;00m ssl_context\u001b[39m.\u001b[39;49mwrap_socket(sock, server_hostname\u001b[39m=\u001b[39;49mserver_hostname)\n\u001b[0;32m    494\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\krish\\anaconda3\\envs\\torch_env\\lib\\ssl.py:513\u001b[0m, in \u001b[0;36mSSLContext.wrap_socket\u001b[1;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[0;32m    507\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrap_socket\u001b[39m(\u001b[39mself\u001b[39m, sock, server_side\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    508\u001b[0m                 do_handshake_on_connect\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    509\u001b[0m                 suppress_ragged_eofs\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    510\u001b[0m                 server_hostname\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, session\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    511\u001b[0m     \u001b[39m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[0;32m    512\u001b[0m     \u001b[39m# ctx._wrap_socket()\u001b[39;00m\n\u001b[1;32m--> 513\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msslsocket_class\u001b[39m.\u001b[39;49m_create(\n\u001b[0;32m    514\u001b[0m         sock\u001b[39m=\u001b[39;49msock,\n\u001b[0;32m    515\u001b[0m         server_side\u001b[39m=\u001b[39;49mserver_side,\n\u001b[0;32m    516\u001b[0m         do_handshake_on_connect\u001b[39m=\u001b[39;49mdo_handshake_on_connect,\n\u001b[0;32m    517\u001b[0m         suppress_ragged_eofs\u001b[39m=\u001b[39;49msuppress_ragged_eofs,\n\u001b[0;32m    518\u001b[0m         server_hostname\u001b[39m=\u001b[39;49mserver_hostname,\n\u001b[0;32m    519\u001b[0m         context\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m    520\u001b[0m         session\u001b[39m=\u001b[39;49msession\n\u001b[0;32m    521\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\krish\\anaconda3\\envs\\torch_env\\lib\\ssl.py:1071\u001b[0m, in \u001b[0;36mSSLSocket._create\u001b[1;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[0;32m   1070\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1071\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdo_handshake()\n\u001b[0;32m   1072\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mOSError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\krish\\anaconda3\\envs\\torch_env\\lib\\ssl.py:1342\u001b[0m, in \u001b[0;36mSSLSocket.do_handshake\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m   1341\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msettimeout(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m-> 1342\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mdo_handshake()\n\u001b[0;32m   1343\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "\u001b[1;31mProtocolError\u001b[0m: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mPineconeProtocolError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\krish\\OneDrive\\Desktop\\Study\\Gen AI\\Gen AI - MediaBot\\test_data.ipynb Cell 4\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/krish/OneDrive/Desktop/Study/Gen%20AI/Gen%20AI%20-%20MediaBot/test_data.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m data_obj \u001b[39m=\u001b[39m Data(pdf_data_path,pdf_vector_embedding_path)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/krish/OneDrive/Desktop/Study/Gen%20AI/Gen%20AI%20-%20MediaBot/test_data.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m test_question \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mWhat are the cons of Sony ZV-E1 Camera ?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/krish/OneDrive/Desktop/Study/Gen%20AI/Gen%20AI%20-%20MediaBot/test_data.ipynb#X10sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m result \u001b[39m=\u001b[39m data_obj\u001b[39m.\u001b[39;49mcreate_top_k_chunk_from_Pinecone(test_question, top_k\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/krish/OneDrive/Desktop/Study/Gen%20AI/Gen%20AI%20-%20MediaBot/test_data.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m result\n",
      "\u001b[1;32mc:\\Users\\krish\\OneDrive\\Desktop\\Study\\Gen AI\\Gen AI - MediaBot\\test_data.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/krish/OneDrive/Desktop/Study/Gen%20AI/Gen%20AI%20-%20MediaBot/test_data.ipynb#X10sZmlsZQ%3D%3D?line=255'>256</a>\u001b[0m index \u001b[39m=\u001b[39m pc\u001b[39m.\u001b[39mIndex(\u001b[39m'\u001b[39m\u001b[39mpdf-index\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/krish/OneDrive/Desktop/Study/Gen%20AI/Gen%20AI%20-%20MediaBot/test_data.ipynb#X10sZmlsZQ%3D%3D?line=256'>257</a>\u001b[0m vectorstore \u001b[39m=\u001b[39m Pinecone( index, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mopenai_embedding_model\u001b[39m.\u001b[39membed_query, text_key\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpage_content\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/krish/OneDrive/Desktop/Study/Gen%20AI/Gen%20AI%20-%20MediaBot/test_data.ipynb#X10sZmlsZQ%3D%3D?line=257'>258</a>\u001b[0m top_k_chunks \u001b[39m=\u001b[39m vectorstore\u001b[39m.\u001b[39;49msimilarity_search(question, k\u001b[39m=\u001b[39;49mtop_k)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/krish/OneDrive/Desktop/Study/Gen%20AI/Gen%20AI%20-%20MediaBot/test_data.ipynb#X10sZmlsZQ%3D%3D?line=258'>259</a>\u001b[0m \u001b[39mreturn\u001b[39;00m top_k_chunks\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\langchain\\vectorstores\\pinecone.py:200\u001b[0m, in \u001b[0;36mPinecone.similarity_search\u001b[1;34m(self, query, k, filter, namespace, **kwargs)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msimilarity_search\u001b[39m(\n\u001b[0;32m    182\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    183\u001b[0m     query: \u001b[39mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[0;32m    188\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[Document]:\n\u001b[0;32m    189\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return pinecone documents most similar to query.\u001b[39;00m\n\u001b[0;32m    190\u001b[0m \n\u001b[0;32m    191\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39m        List of Documents most similar to the query and score for each\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m     docs_and_scores \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msimilarity_search_with_score(\n\u001b[0;32m    201\u001b[0m         query, k\u001b[39m=\u001b[39mk, \u001b[39mfilter\u001b[39m\u001b[39m=\u001b[39m\u001b[39mfilter\u001b[39m, namespace\u001b[39m=\u001b[39mnamespace, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    202\u001b[0m     )\n\u001b[0;32m    203\u001b[0m     \u001b[39mreturn\u001b[39;00m [doc \u001b[39mfor\u001b[39;00m doc, _ \u001b[39min\u001b[39;00m docs_and_scores]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\langchain\\vectorstores\\pinecone.py:145\u001b[0m, in \u001b[0;36mPinecone.similarity_search_with_score\u001b[1;34m(self, query, k, filter, namespace)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msimilarity_search_with_score\u001b[39m(\n\u001b[0;32m    128\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    129\u001b[0m     query: \u001b[39mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    132\u001b[0m     namespace: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    133\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[Tuple[Document, \u001b[39mfloat\u001b[39m]]:\n\u001b[0;32m    134\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return pinecone documents most similar to query, along with scores.\u001b[39;00m\n\u001b[0;32m    135\u001b[0m \n\u001b[0;32m    136\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[39m        List of Documents most similar to the query and score for each\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 145\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msimilarity_search_by_vector_with_score(\n\u001b[0;32m    146\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_embed_query(query), k\u001b[39m=\u001b[39;49mk, \u001b[39mfilter\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mfilter\u001b[39;49m, namespace\u001b[39m=\u001b[39;49mnamespace\n\u001b[0;32m    147\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\langchain\\vectorstores\\pinecone.py:162\u001b[0m, in \u001b[0;36mPinecone.similarity_search_by_vector_with_score\u001b[1;34m(self, embedding, k, filter, namespace)\u001b[0m\n\u001b[0;32m    160\u001b[0m     namespace \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_namespace\n\u001b[0;32m    161\u001b[0m docs \u001b[39m=\u001b[39m []\n\u001b[1;32m--> 162\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_index\u001b[39m.\u001b[39;49mquery(\n\u001b[0;32m    163\u001b[0m     [embedding],\n\u001b[0;32m    164\u001b[0m     top_k\u001b[39m=\u001b[39;49mk,\n\u001b[0;32m    165\u001b[0m     include_metadata\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    166\u001b[0m     namespace\u001b[39m=\u001b[39;49mnamespace,\n\u001b[0;32m    167\u001b[0m     \u001b[39mfilter\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mfilter\u001b[39;49m,\n\u001b[0;32m    168\u001b[0m )\n\u001b[0;32m    169\u001b[0m \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m results[\u001b[39m\"\u001b[39m\u001b[39mmatches\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m    170\u001b[0m     metadata \u001b[39m=\u001b[39m res[\u001b[39m\"\u001b[39m\u001b[39mmetadata\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\krish\\anaconda3\\envs\\torch_env\\lib\\site-packages\\pinecone\\core\\utils\\error_handling.py:25\u001b[0m, in \u001b[0;36mvalidate_and_convert_errors.<locals>.inner_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[39mraise\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[39mexcept\u001b[39;00m ProtocolError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m---> 25\u001b[0m     \u001b[39mraise\u001b[39;00m PineconeProtocolError(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFailed to connect; did you specify the correct index name?\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "\u001b[1;31mPineconeProtocolError\u001b[0m: Failed to connect; did you specify the correct index name?"
     ]
    }
   ],
   "source": [
    "pdf_data_path = \".\\\\media\"\n",
    "pdf_vector_embedding_path = \".\\\\VectorDB\"\n",
    "data_obj = Data(pdf_data_path,pdf_vector_embedding_path)\n",
    "test_question = \"What are the cons of Sony ZV-E1 Camera ?\"\n",
    "result = data_obj.create_top_k_chunk_from_Pinecone(test_question, top_k=3)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import re\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.schema import SystemMessage\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, MessagesPlaceholder\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "class Model:\n",
    "    def __init__(self):\n",
    "        self.openai_api_key = os.getenv(\"OPENAI_KEY\")\n",
    "        self.model = 'text-davinci-003'\n",
    "        self.llm = ChatOpenAI( openai_api_key = os.getenv(\"OPENAI_KEY\"))\n",
    "\n",
    "    def createQuestionPrompt(self, top_k_chunks):\n",
    "        prompt= \"\"\n",
    "        prompt += 'Context:\\n\\n'\n",
    "        for i in range(len(top_k_chunks)):\n",
    "            page_content = top_k_chunks[i].page_content.replace('\\n', ' ')\n",
    "            page_content = re.sub('\\s+', ' ', page_content)\n",
    "            prompt += page_content +'\\n\\n'\n",
    "        prompt += '''\\nInstructions: Compose a comprehensive reply to the query asked by the user from the context provided.\n",
    "        Cite each reference using [pdfname.pdf , page : number] notation (every result has this number at the beginning and end).\n",
    "        Citation should be done at the end of each sentence. If the search results mention multiple subjects\n",
    "        with the same name, create separate answers for each. Only include information found in the results and\n",
    "        don't add any additional information. Make sure the answer is correct and don't output false content.\n",
    "        If the text does not relate to the query, simply state 'Found Nothing'. Don't write 'Answer:'\n",
    "        Directly start the answer.\\n'''.replace('\\\\n',' ')\n",
    "    \n",
    "        return prompt\n",
    "    \n",
    "    def createQuestionPromptTemplate(self, prompt):\n",
    "        prompt_template_llmchain = ChatPromptTemplate.from_messages([\n",
    "                    SystemMessage(content=f\"You are a QnA Chatbot whose job is to greet the user politely and asnwer to the question they ask.\"+prompt), \n",
    "                    MessagesPlaceholder(variable_name=\"chat_history\"),         # Where the memory will be stored.\n",
    "                    HumanMessagePromptTemplate.from_template(\"{human_input}\"), # Where the human input will injected\n",
    "                 ])\n",
    "        \n",
    "        return prompt_template_llmchain\n",
    "    \n",
    "    def generateAnswer(self, prompt):\n",
    "        openai.api_key = self.openai_api_key\n",
    "        completions = openai.Completion.create(\n",
    "            engine=self.model,\n",
    "            prompt=prompt,\n",
    "            max_tokens=1024,\n",
    "            temperature=0,\n",
    "        )\n",
    "        answer = completions.choices[0]['text']\n",
    "        return answer\n",
    "    \n",
    "    def generateAnswerwithMemory(self,question, prompt_template, chat_history):\n",
    "        memory = ConversationBufferWindowMemory(memory_key=\"chat_history\", return_messages=True, k=3)\n",
    "        llm = ChatOpenAI(openai_api_key = os.getenv(\"OPENAI_KEY\"),model='gpt-3.5-turbo')\n",
    "        llm_chain = LLMChain(\n",
    "            llm=llm,\n",
    "            prompt=prompt_template,\n",
    "            verbose=True,\n",
    "            memory=memory,\n",
    "        )\n",
    "\n",
    "        llm_chain_response = llm_chain.predict(human_input = question)\n",
    "        interaction = 'human:'+question+'\\nchatbot:'+llm_chain_response\n",
    "        chat_history.append(interaction)\n",
    "        return llm_chain_response\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a QnA Chatbot whose job is to greet the user politely and asnwer to the question they ask.Context:\n",
      "\n",
      "key to a nation’s progress. Our government is committed to providing a transparent and accountable administration which works for the betterment and welfare of the common citizen,” said Hon’ble Prime Minister. [budget_2023.pdf, page:17].[budget_2023.pdf, page:18] 14 Mission Karmayogi 58. Under Mission Karmayogi, Centre, States and Union Territories are making and implementing capacity-building plans for civil servants. The government has also launched an integrated online training platform, iGOT Karmayogi, to provide continuous learning opportunities for lakhs of government employees to upgrade their skills and facilitate people-centric approach. 59. For enhancing ease of doing business, more than 39,000 compliances have been reduced and more than 3,400 legal provisions have been decriminalized. For furthering the trust- based governance, we have introduced the Jan Vishwas Bill to amend 42 Central Acts. This Budget proposes a series of measures to unleash the potential of our economy. Centres of Excellence for Artificial Intelligence 60. For realizing the vision of “Make AI in India and Make AI work for India”, three centres of excellence for Artificial Intelligence will be set-up in top educational institutions. Leading industry players will partner in conducting interdisciplinary research, develop cutting-edge applications and scalable problem solutions in the areas of agriculture, health, and sustainable cities. This will galvanize an effective AI ecosystem and nurture quality human resources in the field. National Data Governance Policy 61. To unleash innovation and research by start-ups and academia, a National Data Governance Policy will be brought out. This will enable access to anonymized data. Simplification of Know Your Customer (KYC) process 62. The KYC process will be simplified adopting a ‘risk-based’ instead of ‘one size fits all’ approach. The financial sector regulators will also be [budget_2023.pdf, page:18].[budget_2023.pdf, page:19] 15 encouraged\n",
      "\n",
      "Inscriptions’ will be set up in a digital epigraphy museum, with digitization of one lakh ancient inscriptions in the first stage. Support for poor prisoners 42. For poor persons who are in prisons and unable to afford the penalty or the bail amount, required financial support will be provided. Priority 3: Infrastructure & Investment 43. Investments in Infrastructure and productive capacity have a large multiplier impact on growth and employment. After the subdued period of the pandemic, private investments are growing again. The Budget takes the lead once again to ramp up the virtuous cycle of investment and job creation. Capital Investment as driver of growth and jobs 44. Capital investment outlay is being increased steeply for the third year in a row by 33 per cent to ` 10 lakh crore, which would be 3.3 per cent of GDP. This will be almost three times the outlay in 2019-20. 45. This substantial increase in recent years is central to the government’s efforts to enhance growth potential and job creation, crowd- in private investments, and provide a cushion against global headwinds. Effective Capital Expenditure 46. The direct capital investment by the Centre is complemented by the provision made for creation of capital assets through Grants-in-Aid to States. The ‘Effective Capital Expenditure’ of the Centre is budgeted at ` 13.7 lakh crore, which will be 4.5 per cent of GDP. [budget_2023.pdf, page:15].[budget_2023.pdf, page:16] 12 Support to State Governments for Capital Investment 47. I have decided to continue the 50-year interest free loan to state governments for one more year to spur investment in infrastructure and to incentivize them for complementary policy actions, with a significantly enhanced outlay of ` 1.3 lakh crore. Enhancing opportunities for private investment in Infrastructure 48. The newly established Infrastructure Finance Secretariat will assist all stakeholders for more private investment in infrastructure, including railways, roads, urban\n",
      "\n",
      "payments, and social security. This will greatly benefit the Scheduled Castes, Scheduled Tribes, OBCs, women and people belonging to the weaker sections. 3) Tourism: The country offers immense attraction for domestic as well as foreign tourists. There is a large potential to be tapped in tourism. The sector holds huge opportunities for jobs and entrepreneurship for youth in particular. Promotion of tourism will be taken up on mission mode, with active participation of states, convergence of government programmes and public-private partnerships. [budget_2023.pdf, page:8].[budget_2023.pdf, page:9] 5 4) Green Growth: We are implementing many programmes for green fuel, green energy, green farming, green mobility, green buildings, and green equipment, and policies for efficient use of energy across various economic sectors. These green growth efforts help in reducing carbon intensity of the economy and provides for large- scale green job opportunities. Priorities of this Budget 14. The Budget adopts the following seven priorities. They complement each other and act as the ‘Saptarishi’ guiding us through the Amrit Kaal. 1) Inclusive Development 2) Reaching the Last Mile 3) Infrastructure and Investment 4) Unleashing the Potential 5) Green Growth 6) Youth Power 7) Financial Sector Priority 1: Inclusive Development 15. The Government’s philosophy of Sabka Saath Sabka Vikas has facilitated inclusive development covering in specific, farmers, women, youth, OBCs, Scheduled Castes, Scheduled Tribes, divyangjan and economically weaker sections, and overall priority for the underprivileged (vanchiton ko variyata). There has also been a sustained focus on Jammu & Kashmir, Ladakh and the North-East. This Budget builds on those efforts. Agriculture and Cooperation Digital Public Infrastructure for Agriculture 16. Digital public infrastructure for agriculture will be built as an open source, open standard and inter operable public good. This will enable [budget_2023.pdf,\n",
      "\n",
      "\n",
      "Instructions: Compose a comprehensive reply to the query asked by the user from the context provided.\n",
      "        Cite each reference using [pdfname.pdf , page : number] notation (every result has this number at the beginning and end).\n",
      "        Citation should be done at the end of each sentence. If the search results mention multiple subjects\n",
      "        with the same name, create separate answers for each. Only include information found in the results and\n",
      "        don't add any additional information. Make sure the answer is correct and don't output false content.\n",
      "        If the text does not relate to the query, simply state 'Found Nothing'. Don't write 'Answer:'\n",
      "        Directly start the answer.\n",
      "\n",
      "Human: Artificial Intelligence in budget?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model_obj = Model()\n",
    "prompt = model_obj.createQuestionPrompt(result)\n",
    "prompt_template = model_obj.createQuestionPromptTemplate(prompt)\n",
    "response = model_obj.generateAnswerwithMemory(test_question, prompt_template,chat_history=[])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Three centers of excellence for Artificial Intelligence will be set up in top educational institutions under the vision of \"Make AI in India and Make AI work for India\" [budget_2023.pdf, page: 18]. These centers will partner with leading industry players to conduct interdisciplinary research, develop cutting-edge applications, and provide scalable problem solutions in the areas of agriculture, health, and sustainable cities. The goal is to create an effective AI ecosystem and nurture quality human resources in the field [budget_2023.pdf, page: 18].'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_obj = Model()\n",
    "prompt = model_obj.createQuestionPrompt(result)\n",
    "prompt_template = model_obj.createQuestionPromptTemplate(prompt)\n",
    "response = model_obj.generateAnswerwithMemory(test_question, prompt_template,chat_history=[])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
